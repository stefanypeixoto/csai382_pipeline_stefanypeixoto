{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2a7097-3854-4fb2-8c7e-7528464725a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark = spark.table(\"labeled_step_test\")\n",
    "df = df_spark.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d455a3fc-e6ea-4114-aa65-715005cb211b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols_numeric = [\"distance_cm\"]\n",
    "feature_cols_categorical = [\"sensor_type\", \"device_id\"]\n",
    "label_col = \"step_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba581942-716b-4b8d-922b-4192f0cca77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[feature_cols_numeric + feature_cols_categorical]\n",
    "y = df[label_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3a1e83-1e40-4ae1-bf5d-6cc1fc2b8a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0fcb79-d377-42a4-bc9a-18c1d84e096f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bc457a-a6cf-486f-9ff7-075b08317b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, feature_cols_numeric),\n",
    "        (\"cat\", categorical_transformer, feature_cols_categorical)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83eedc18-2e53-4fa3-97cc-0b0ef586bd1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f406786a-0ee9-463d-9258-7fe957256ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train)\n",
    "\n",
    "X_train_transformed = pipeline.transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28749125-39b1-4597-b04d-04e3064c399f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "base_path = \"/tmp/etl_pipeline/\"\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "    print(f\"Created directory: {base_path}\")\n",
    "\n",
    "joblib.dump(pipeline, os.path.join(base_path, \"stedi_feature_pipeline.pkl\"))\n",
    "joblib.dump(X_train_transformed, os.path.join(base_path, \"X_train_transformed.pkl\"))\n",
    "joblib.dump(X_test_transformed, os.path.join(base_path, \"X_test_transformed.pkl\"))\n",
    "joblib.dump(y_test, os.path.join(base_path, \"y_test.pkl\"))\n",
    "joblib.dump(y_train, os.path.join(base_path, \"y_train.pkl\"))\n",
    "\n",
    "print(\"All files saved successfully to /tmp/etl_pipeline/!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25602293-7e49-4702-82b0-27499f474425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Ethics Reflection\n",
    "\n",
    "Using a consistent, reproducible feature pipeline prevents unfairness by ensuring that every data point, regardless of its source, is treated with the exact same mathematical logic. In Machine Learning, \"hidden bias\" often creeps in when we process different groups of data inconsistently, but a pipeline locks our preprocessing (like scaling and encoding) into a stable standard. This technical consistency mirrors the spiritual principle of Equity, as taught in the scriptures: God is \"no respecter of persons\" (Acts 10:34) and operates by unchanging laws. By building reliable pipelines, we ensure our models do not favor certain device types or demographics due to sloppy or varied data handling. Just as consistent spiritual habits build a stable foundation, consistent data habits build trustworthy and fair AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d5b1b6-40cb-4df5-a35b-29e2e70a57c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "base_path = \"/tmp/etl_pipeline/\"\n",
    "\n",
    "pipeline = joblib.load(base_path + \"stedi_feature_pipeline.pkl\")\n",
    "X_train_transformed = joblib.load(base_path + \"X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(base_path + \"X_test_transformed.pkl\")\n",
    "y_train = joblib.load(base_path + \"y_train.pkl\")\n",
    "y_test = joblib.load(base_path + \"y_test.pkl\")\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "    This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "    and ML models require numeric 2-D arrays for training and prediction.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2076be00-c508-4702-a05b-e3542b5257a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "882349a1-36e4-405d-985e-77e11ca99671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0817da-cf60-4d6f-ae25-5acc280ddc84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18597bba-50e0-47b7-93d0-1ce14dbb4c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Baseline Model Analysis\n",
    "\n",
    "In this baseline evaluation, the Logistic Regression model performed slightly better with an accuracy of 95.11%, compared to 95.09% for the Random Forest. While Logistic Regression was marginally more accurate here, Random Forest often proves more stable for noisy sensor data because its ensemble nature (using multiple decision trees) is less likely to be \"tricked\" by individual outliers or sensor glitches.\n",
    "\n",
    "The fact that the numbers are so close, and so high, leads me to wonder if the distance_cm feature provides a very clear linear signal for a \"step,\" or if the dataset is well-balanced. It is important to test these models before deployment because an untested model could provide false health metrics; a wrong prediction could affect patients relying on accurate step counts for rehabilitation or elderly monitoring. Therefore, fairness matters in data science just as it does in discipleship because we have a responsibility to ensure our tools serve everyone equitably. Just as we are called to treat all people with integrity, our models must not harbor \"hidden\" biases that disadvantage certain users based on their device data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d175f34-2215-4c1f-87d8-5630175e3f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a unique folder name (prevents overwriting files)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir = f\"/Workspace/Users/stef4@ensign.edu/stedi_models/{run_id}\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(log_reg, f\"{base_dir}/log_reg.joblib\")\n",
    "joblib.dump(rf, f\"{base_dir}/random_forest.joblib\")\n",
    "\n",
    "# Save accuracy information (metadata)\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"logistic_regression_accuracy\": float(log_reg_score),\n",
    "    \"random_forest_accuracy\": float(rf_score),\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, f\"{base_dir}/metadata.joblib\")\n",
    "\n",
    "base_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49fcafb3-f567-4d8e-af8a-a398f4985bc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "zip_path = f\"/Workspace/Users/stef4@ensign.edu/stedi_models/{run_id}.zip\"\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), \"zip\", base_dir)\n",
    "zip_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f42dc81-3dcc-4aab-ba13-528664247b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5.3 Trained ML Models: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79007e9f-d14e-45ec-ba8f-ed46992f9df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg_params = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "log_reg_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=300),\n",
    "    log_reg_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "\n",
    "log_reg_best_params = log_reg_grid.best_params_\n",
    "log_reg_best_score = log_reg_grid.best_score_\n",
    "\n",
    "log_reg_best_params, log_reg_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7368e2d-5f97-4a3b-8304-1dd6566e0981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    rf_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_best_params = rf_grid.best_params_\n",
    "rf_best_score = rf_grid.best_score_\n",
    "\n",
    "rf_best_params, rf_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26a918c4-3fae-4b7f-8817-9302c72828b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression (tuned)\": log_reg_best_score,\n",
    "    \"Random Forest (tuned)\": rf_best_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d426ef47-802d-4f86-939a-825ee37f5230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Choose the better model based on best_score_\n",
    "if rf_best_score > log_reg_best_score:\n",
    "    best_model = rf_grid.best_estimator_\n",
    "    best_model_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = log_reg_grid.best_estimator_\n",
    "    best_model_name = \"Logistic Regression\"\n",
    "\n",
    "best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70619c49-7f9c-439a-b1c0-55a995792894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_path = \"/Workspace/Users/stef4@ensign.edu/stedi_models/stedi_best_model.pkl\"\n",
    "joblib.dump(best_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953ab3f7-1b66-4a49-bdbc-06e596938bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Successfully saved the {best_model_name} model to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9b4a72e-d4f0-4416-8961-cec64ef357ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5.3 Model Evaluation Report\n",
    "\n",
    "After running hyperparameter tuning, both the Logistic Regression and Random Forest models achieved an identical cross-validation accuracy of 95.11%. This suggests that the signal in the STEDI sensor data is strong enough that even a linear model can capture it as effectively as a complex ensemble of trees. I chose to proceed with the [Random Forest / Logistic Regression] as my final model.\n",
    "\n",
    "##Ethics Reflection\n",
    "\n",
    "Hyperparameter tuning can accidentally introduce bias if we optimize solely for a single global metric like accuracy. For example, a specific setting might increase the overall score by better predicting the majority group while significantly decreasing performance for a smaller demographic. This creates a \"hidden\" unfairness that documentation and transparency help reveal. Transparency is essential because it allows others to audit our choices and ensure the model serves everyone equitably. The gospel principle of Honest Evaluation reminds us that \"by small and simple things are great things brought to pass\" (Alma 37:6); being truthful about our model’s limitations is just as important as reporting its successes. We have a responsibility to seek light and truth in our data, ensuring our technical work reflects integrity and accountability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a20516e9-372f-482f-8033-96d9648e1b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = rf_grid.best_estimator_\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a1a8e2d-27f7-46a6-a5d3-10e215562fec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "importances = model.feature_importances_\n",
    "importance_order = np.argsort(importances)[::-1]\n",
    "\n",
    "# Get feature names if available\n",
    "try:\n",
    "    feature_names = pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "for idx in importance_order[:10]:\n",
    "    print(feature_names[idx], \":\", importances[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56b72bcf-8f00-4400-bf1f-ae8cfcd268a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Analysis: Feature Importance\n",
    "\n",
    "Do the most important features make sense?\n",
    "\n",
    "Yes, it makes sense that distance_cm is a primary indicator. If the STEDI device is measuring the distance from a sensor to a person's leg or the floor, that distance will change drastically and consistently every time a step is taken. The fact that different sensor types (gyroscope vs. accelerometer) also appear shows the model is using motion data, but they are dwarfed by the distance metric.\n",
    "\n",
    "Are there any surprises?\n",
    "\n",
    "The biggest surprise is how much the model relies on distance_cm. Having one feature account for over 92% of the importance is unusual. It suggests the model has found a \"shortcut.\" Also, it’s interesting that specific device_id values (like spotter-14) show up in the top 10. Ideally, a model should predict steps based on how a person moves, not which specific device they are using.\n",
    "\n",
    "Would you trust predictions made with this importance pattern?\n",
    "\n",
    "I would trust them, but with caution. Because the model is so dependent on one feature, if that distance sensor gets dusty, blocked, or glitches, the entire model's accuracy will likely collapse. For a high-stakes informatics application, we usually prefer a more balanced model that uses multiple sensors (accelerometer + gyro + distance) so that there is \"redundancy\" if one sensor fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfdbccb4-9fd0-4ae1-9066-ca1ffcd62d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "    importance_order = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Get feature names if available\n",
    "    try:\n",
    "        feature_names = pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "    except Exception:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "    # Print top 10\n",
    "    for idx in importance_order[:10]:\n",
    "        print(feature_names[idx], \":\", importances[idx])\n",
    "\n",
    "    # Plot only if we have importances\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.barh(\n",
    "        [feature_names[i] for i in importance_order[:10]],\n",
    "        importances[importance_order[:10]],\n",
    "    )\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(\"Top Global Feature Importance\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Feature importances are not available for this model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcba22d-6484-472f-bd91-eb4c6bcf3f81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86489b04-2f70-48c4-95fa-a73219526fd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aeee840-087d-4585-9367-febb83f6993d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify the output\n",
    "print(f\"SHAP values calculated. Type: {type(shap_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7c8dc13-0255-4b2a-8629-f1ac64f3c51f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[...,1], X_test, feature_names=feature_names, rng=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9c3686a-bf4c-4df7-a0e5-b1b212006771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###SHAP Summary Plot Observations\n",
    "Match with Global Importance: The SHAP plot confirms the global importance chart; num__distance_cm is overwhelmingly the most influential feature, as it shows the widest spread of SHAP values.\n",
    "\n",
    "Direction of Influence: * For num__distance_cm, blue dots (low distance values) are clustered on the right side of the center line, meaning lower distances push the model toward predicting a step.\n",
    "\n",
    "Red dots (high distance values) are mostly on the left, pushing the prediction toward no_step.\n",
    "\n",
    "Unexpected Influences: It is surprising that the specific device_id (like spotter-14 and spotter-26) has a visible impact. In a robust model, the physical movement (accelerometer/gyro) should matter more than which specific hardware is being used, suggesting the model might be slightly overfitted to specific devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea3eb233-2de6-42ba-92ac-4522e10e98d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "i = 0  # choose any index you like\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[...,1][i],\n",
    "                X_test[i],\n",
    "                feature_names=feature_names,\n",
    "                matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69e266b7-d28f-4a09-a43c-67fd6a34a85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###SHAP Force Plot Interpretation\n",
    "Do you understand the explanation?\n",
    "\n",
    "Yes. The force plot shows the \"tug-of-war\" between features that push the prediction away from the base value. The red arrows (like cat__sensor_type_accelerometer) are pushing the probability \"higher\" toward a step, while the blue arrows (like num__distance_cm and a specific device_id) are pulling it \"lower.\" The final result is the bold value of 0.94.\n",
    "\n",
    "Do features that push toward “step” match your expectations?\n",
    "\n",
    "Mostly, yes. Seeing the accelerometer as a positive (red) force makes sense, as physical movement is the primary indicator of a step. However, it is interesting that for this specific instance, the distance_cm value is actually acting as a negative (blue) force, meaning this particular distance reading made the model less certain it was a step compared to the average.\n",
    "\n",
    "Would you reach the same conclusion if you looked at the data yourself?\n",
    "\n",
    "If I saw a high reading from the accelerometer (value = 1.0) alongside a distance reading of ~0.58, I would likely agree that some form of movement is occurring. However, because the distance feature is so dominant globally, it’s harder for a human to weigh these small decimal differences as precisely as the model does. The visualization helps bridge that gap by showing exactly how the model balances the sensor types against the distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eb35b4e-08ed-4182-9c40-38bcc02cb199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Final Reflection Questions\n",
    "Since you are at the end, here is a concise block to answer the final reflection section:\n",
    "\n",
    "Global Insight: The num__distance_cm feature is the most important overall, likely because the proximity of the user's leg to the sensor provides a very clean signal for walking patterns.\n",
    "\n",
    "Local Insight: The SHAP force plot revealed that while the accelerometer pushed the prediction up, the distance and device ID pulled it slightly down for this specific row, resulting in a 94% probability.\n",
    "\n",
    "Human Intuition Check: The logic mostly matches; movement (accelerometer) should predict a step. However, the heavy reliance on a single distance feature might be a \"shortcut\" that a human might be more skeptical of in varied environments.\n",
    "\n",
    "Dashboard Preparation: I plan to include the Global Feature Importance bar chart and the SHAP Summary Plot. These provide a clear \"personality portrait\" of the model for the Week 7 dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deaf0f85-af75-4ec3-ae13-69c3b3cf63dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix for your extra credit enhancement\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aca2b4c6-111b-413d-8dda-0059add8a16a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SHOW CATALOGS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "815717b7-67e9-4968-bd0c-2e96bba20661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "base_path = \"/tmp/etl_pipeline/\"\n",
    "\n",
    "pipeline = joblib.load(base_path + \"stedi_feature_pipeline.pkl\")\n",
    "X_train_transformed = joblib.load(base_path + \"X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(base_path + \"X_test_transformed.pkl\")\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "    This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "    and ML models require numeric 2-D arrays for training and prediction.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "\n",
    "y_train = joblib.load(base_path + \"y_train.pkl\")\n",
    "y_test = joblib.load(base_path + \"y_test.pkl\")\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a14b588-5013-4838-bf1f-1c01d0900ee5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Reflection on SHAP Insights:\n",
    "My previous SHAP analysis revealed that the model relied almost entirely on the distance_cm feature to make predictions. This led to a significant \"accuracy paradox\" where the model had high overall accuracy but 0% recall for the no_step class, meaning it completely failed to identify when a user was at rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe29bef-65c7-4b4b-9e89-feabaf5c896c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Grid Selection Logic:\n",
    "I am choosing a grid that focuses on class_weight and max_depth.\n",
    "\n",
    "class_weight: ['balanced']: This is the most critical adjustment to fix the 0% recall for the no_step class. It forces the model to treat the minority \"rest\" class with higher importance.\n",
    "\n",
    "max_depth: [10, 20]: I am testing a more constrained depth to prevent the model from simply \"memorizing\" the distance_cm patterns and to encourage it to find more generalized patterns in the accelerometer data.\n",
    "\n",
    "n_estimators: [100, 200]: A standard range to ensure the ensemble has enough trees to stabilize predictions without being computationally wasteful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b15067ae-1aad-44d8-96c8-645106467bd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining the focused refinement grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'class_weight': ['balanced'],  # Directly addresses the class imbalance\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grid defined for refinement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96f135b4-e198-4c92-b3dd-e7b72e215095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Refinement Complete!\")\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Best F1 Score: {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ccc8736-f5c1-4054-9319-8c8267247d59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the best model found by the grid search\n",
    "best_refined_model = grid.best_estimator_\n",
    "y_pred = best_refined_model.predict(X_test)\n",
    "\n",
    "print(\"Refined Model Performance:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b29ec3-63b0-41d4-b760-6b10f080830d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "X_test_sample = shap.sample(X_test, 100) \n",
    "\n",
    "explainer = shap.TreeExplainer(grid.best_estimator_)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54e6a28-78c8-484f-b515-9ca85e7f71ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Old vs. New Models\n",
    "\n",
    "Did the new tuning improve performance?\n",
    "Technically, it depends on your goal. While the overall accuracy dropped from ~98% to 71%, the model's functional performance improved significantly because it is no longer \"blind\" to the minority class. Specifically, the recall for no_step moved from 0% to 37%, meaning the model can now actually detect when a user is resting, which it couldn't do before.\n",
    "\n",
    "Will you switch to the new model?\n",
    "Yes. Despite the lower overall accuracy, this refined model is more appropriate for a real-world health application.\n",
    "\n",
    "If not, why is the old model still the better choice?\n",
    "The old model's high accuracy was a \"mirage\" caused by the massive class imbalance. A model that predicts \"walking\" 100% of the time will be 99% accurate if the user walks 99% of the day, but it is useless as a sensor. The new model’s ability to utilize accelerometer interactions makes it a scientifically better choice than the distance-only bias of the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259e69bf-8d69-4cd8-baaf-5cc7fd55a595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "save_dir = \"/Workspace/Users/stef4@ensign.edu/stedi_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(save_dir, \"stedi_best_model_updated.pkl\")\n",
    "joblib.dump(best_model, save_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23fc79f5-08e2-4996-a2f0-27053b030356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Refinement Summary\n",
    "Tuning Details: I adjusted the class_weight to balanced and refined the max_depth to prevent overfitting on the majority class. I chose these specifically to address the \"blind spot\" identified by SHAP, where the model was ignoring accelerometer data in favor of the distance_cm feature.\n",
    "\n",
    "Performance Result: While overall accuracy decreased to 71%, the model’s ability to detect the no_step class improved from 0% recall to 37%. This indicates the model is now actually learning movement patterns rather than just guessing the majority class.\n",
    "\n",
    "Final Decision: I have updated the final model to this refined version.\n",
    "\n",
    "Ethical & Responsible Justification: This decision is more responsible because a health-monitoring sensor that cannot detect rest is fundamentally broken and misleading to the user. Choosing a model with balanced recall ensures that all user states are represented, reducing algorithmic bias against resting periods and providing a more \"honest\" evaluation of activity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "474f9ea5-b9ea-4b77-83d1-f213816edd7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Ethics Reflection\n",
    "\n",
    "Careless hyperparameter tuning can lead to models that prioritize high overall accuracy while marginalizing minority classes, creating a \"veneer\" of performance that hides significant failures. In a health context, an unfair model might consistently fail to detect rest periods, leading to unsafe user behavior or inaccurate medical insights. Examining model behavior through tools like SHAP and classification reports is essential to ensure we are not just optimizing for numbers, but for human safety and truth.\n",
    "\n",
    "The principles that guides me are of integrity and stewardship. Integrity requires me to be honest about a model's limitations, such as admitting that a 98% accurate model is actually broken if it has 0% recall for a specific class. Stewardship reminds me that I am responsible for the \"fruits\" of my labor; as the scripture teaches, \"by their fruits ye shall know them\" (Matthew 7:20). By making careful, intentional tuning decisions, I ensure that my technical work serves others with honesty and accuracy."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.3_Feature_Engineering_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
