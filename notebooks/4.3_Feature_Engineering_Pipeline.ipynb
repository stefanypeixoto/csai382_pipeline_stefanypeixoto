{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2a7097-3854-4fb2-8c7e-7528464725a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark = spark.table(\"labeled_step_test\")\n",
    "df = df_spark.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d455a3fc-e6ea-4114-aa65-715005cb211b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols_numeric = [\"distance_cm\"]\n",
    "feature_cols_categorical = [\"sensor_type\", \"device_id\"]\n",
    "label_col = \"step_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba581942-716b-4b8d-922b-4192f0cca77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[feature_cols_numeric + feature_cols_categorical]\n",
    "y = df[label_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3a1e83-1e40-4ae1-bf5d-6cc1fc2b8a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0fcb79-d377-42a4-bc9a-18c1d84e096f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bc457a-a6cf-486f-9ff7-075b08317b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, feature_cols_numeric),\n",
    "        (\"cat\", categorical_transformer, feature_cols_categorical)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83eedc18-2e53-4fa3-97cc-0b0ef586bd1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f406786a-0ee9-463d-9258-7fe957256ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train)\n",
    "\n",
    "X_train_transformed = pipeline.transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28749125-39b1-4597-b04d-04e3064c399f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "base_path = \"/tmp/etl_pipeline/\"\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "    print(f\"Created directory: {base_path}\")\n",
    "\n",
    "joblib.dump(pipeline, os.path.join(base_path, \"stedi_feature_pipeline.pkl\"))\n",
    "joblib.dump(X_train_transformed, os.path.join(base_path, \"X_train_transformed.pkl\"))\n",
    "joblib.dump(X_test_transformed, os.path.join(base_path, \"X_test_transformed.pkl\"))\n",
    "joblib.dump(y_test, os.path.join(base_path, \"y_test.pkl\"))\n",
    "joblib.dump(y_train, os.path.join(base_path, \"y_train.pkl\"))\n",
    "\n",
    "print(\"All files saved successfully to /tmp/etl_pipeline/!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25602293-7e49-4702-82b0-27499f474425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Ethics Reflection\n",
    "\n",
    "Using a consistent, reproducible feature pipeline prevents unfairness by ensuring that every data point, regardless of its source, is treated with the exact same mathematical logic. In Machine Learning, \"hidden bias\" often creeps in when we process different groups of data inconsistently, but a pipeline locks our preprocessing (like scaling and encoding) into a stable standard. This technical consistency mirrors the spiritual principle of Equity, as taught in the scriptures: God is \"no respecter of persons\" (Acts 10:34) and operates by unchanging laws. By building reliable pipelines, we ensure our models do not favor certain device types or demographics due to sloppy or varied data handling. Just as consistent spiritual habits build a stable foundation, consistent data habits build trustworthy and fair AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d5b1b6-40cb-4df5-a35b-29e2e70a57c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "base_path = \"/tmp/etl_pipeline/\"\n",
    "\n",
    "pipeline = joblib.load(base_path + \"stedi_feature_pipeline.pkl\")\n",
    "X_train_transformed = joblib.load(base_path + \"X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(base_path + \"X_test_transformed.pkl\")\n",
    "y_train = joblib.load(base_path + \"y_train.pkl\")\n",
    "y_test = joblib.load(base_path + \"y_test.pkl\")\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "    This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "    and ML models require numeric 2-D arrays for training and prediction.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2076be00-c508-4702-a05b-e3542b5257a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "882349a1-36e4-405d-985e-77e11ca99671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0817da-cf60-4d6f-ae25-5acc280ddc84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18597bba-50e0-47b7-93d0-1ce14dbb4c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Baseline Model Analysis\n",
    "\n",
    "In this baseline evaluation, the Logistic Regression model performed slightly better with an accuracy of 95.11%, compared to 95.09% for the Random Forest. While Logistic Regression was marginally more accurate here, Random Forest often proves more stable for noisy sensor data because its ensemble nature (using multiple decision trees) is less likely to be \"tricked\" by individual outliers or sensor glitches.\n",
    "\n",
    "The fact that the numbers are so close, and so high, leads me to wonder if the distance_cm feature provides a very clear linear signal for a \"step,\" or if the dataset is well-balanced. It is important to test these models before deployment because an untested model could provide false health metrics; a wrong prediction could affect patients relying on accurate step counts for rehabilitation or elderly monitoring. Therefore, fairness matters in data science just as it does in discipleship because we have a responsibility to ensure our tools serve everyone equitably. Just as we are called to treat all people with integrity, our models must not harbor \"hidden\" biases that disadvantage certain users based on their device data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d175f34-2215-4c1f-87d8-5630175e3f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a unique folder name (prevents overwriting files)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir = f\"/Workspace/Users/stef4@ensign.edu/stedi_models/{run_id}\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(log_reg, f\"{base_dir}/log_reg.joblib\")\n",
    "joblib.dump(rf, f\"{base_dir}/random_forest.joblib\")\n",
    "\n",
    "# Save accuracy information (metadata)\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"logistic_regression_accuracy\": float(log_reg_score),\n",
    "    \"random_forest_accuracy\": float(rf_score),\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, f\"{base_dir}/metadata.joblib\")\n",
    "\n",
    "base_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49fcafb3-f567-4d8e-af8a-a398f4985bc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "zip_path = f\"/Workspace/Users/stef4@ensign.edu/stedi_models/{run_id}.zip\"\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), \"zip\", base_dir)\n",
    "zip_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f42dc81-3dcc-4aab-ba13-528664247b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5.3 Trained ML Models: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79007e9f-d14e-45ec-ba8f-ed46992f9df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg_params = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "log_reg_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=300),\n",
    "    log_reg_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "\n",
    "log_reg_best_params = log_reg_grid.best_params_\n",
    "log_reg_best_score = log_reg_grid.best_score_\n",
    "\n",
    "log_reg_best_params, log_reg_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7368e2d-5f97-4a3b-8304-1dd6566e0981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    rf_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_best_params = rf_grid.best_params_\n",
    "rf_best_score = rf_grid.best_score_\n",
    "\n",
    "rf_best_params, rf_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26a918c4-3fae-4b7f-8817-9302c72828b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression (tuned)\": log_reg_best_score,\n",
    "    \"Random Forest (tuned)\": rf_best_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d426ef47-802d-4f86-939a-825ee37f5230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Choose the better model based on best_score_\n",
    "if rf_best_score > log_reg_best_score:\n",
    "    best_model = rf_grid.best_estimator_\n",
    "    best_model_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = log_reg_grid.best_estimator_\n",
    "    best_model_name = \"Logistic Regression\"\n",
    "\n",
    "best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70619c49-7f9c-439a-b1c0-55a995792894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_path = \"/Workspace/Users/stef4@ensign.edu/stedi_models/stedi_best_model.pkl\"\n",
    "joblib.dump(best_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953ab3f7-1b66-4a49-bdbc-06e596938bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Successfully saved the {best_model_name} model to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9b4a72e-d4f0-4416-8961-cec64ef357ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5.3 Model Evaluation Report\n",
    "\n",
    "After running hyperparameter tuning, the Logistic Regression model performed best, achieving a cross-validation accuracy of 95.11%. I identified this by comparing the best_score_ from the GridSearchCV results for both models. For Logistic Regression, the best performance came from using a C value of 0.01, which applied strong regularization to simplify the model and prevent overfitting to sensor noise. It was somewhat surprising that the simpler Logistic Regression outperformed the complex Random Forest, but this suggests that the relationship between the accelerometer data and the step labels is relatively linear and well-defined. If I had more time, I would test XGBoost or Gradient Boosting models to see if boosting techniques could squeeze out even higher accuracy, or I would perform deeper feature engineering on the time-series sensor data.\n",
    "\n",
    "##Ethics Reflection\n",
    "\n",
    "Hyperparameter tuning can accidentally introduce bias if we optimize solely for a single global metric like accuracy. For example, a specific setting might increase the overall score by better predicting the majority group while significantly decreasing performance for a smaller demographic. This creates a \"hidden\" unfairness that documentation and transparency help reveal. Transparency is essential because it allows others to audit our choices and ensure the model serves everyone equitably. The gospel principle of Honest Evaluation reminds us that \"by small and simple things are great things brought to pass\" (Alma 37:6); being truthful about our modelâ€™s limitations is just as important as reporting its successes. We have a responsibility to seek light and truth in our data, ensuring our technical work reflects integrity and accountability.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.3_Feature_Engineering_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
